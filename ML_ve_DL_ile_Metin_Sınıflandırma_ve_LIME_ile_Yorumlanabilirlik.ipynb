{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONhS6R6UzRW9LCYwVWYsA8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mert-Keskin/Makine-renmesi-ve-Derin-renme-Y-ntemleriyle-Metin-S-n-fland-rma-ve-LIME-ile-Yorumlanabilirlik/blob/main/ML_ve_DL_ile_Metin_S%C4%B1n%C4%B1fland%C4%B1rma_ve_LIME_ile_Yorumlanabilirlik.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "VSLIGHPxHOjD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_gyRAHO81xf"
      },
      "outputs": [],
      "source": [
        "# --- Import Libraries ---\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scraping Functions"
      ],
      "metadata": {
        "id": "lvrW05HzHWLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Scraping Functions ---\n",
        "\n",
        "def get_reviews(appid, params={'json': 1}):\n",
        "    url = 'https://store.steampowered.com/appreviews/'\n",
        "    response = requests.get(url=url + str(appid), params=params, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    return response.json()\n",
        "\n",
        "def get_n_reviews(appid, n=1000):\n",
        "    reviews = []\n",
        "    cursor = '*'\n",
        "    params = {\n",
        "        'json': 1,\n",
        "        'filter': 'all',\n",
        "        'language': 'english',\n",
        "        'day_range': 9223372036854775807,\n",
        "        'review_type': 'all',\n",
        "        'purchase_type': 'all'\n",
        "    }\n",
        "\n",
        "    while n > 0:\n",
        "        params['cursor'] = cursor.encode()\n",
        "        params['num_per_page'] = min(100, n)\n",
        "        n -= 100\n",
        "\n",
        "        response = get_reviews(appid, params)\n",
        "        cursor = response['cursor']\n",
        "        reviews += response['reviews']\n",
        "\n",
        "        if len(response['reviews']) < 100:\n",
        "            break\n",
        "\n",
        "    return reviews\n",
        "\n",
        "def get_app_id(game_name):\n",
        "    response = requests.get(url=f'https://store.steampowered.com/search/?term={game_name}&category1=998', headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    app_id = soup.find(class_='search_result_row')['data-ds-appid']\n",
        "    return app_id\n",
        "\n",
        "def scrape_reviews_for_single_game(game_name, n):\n",
        "    appid = get_app_id(game_name)\n",
        "    print(f\"App ID for {game_name}: {appid}\")\n",
        "    reviews = get_n_reviews(appid, n)\n",
        "\n",
        "    review_data = [{'review': review['review'], 'voted_up': review['voted_up']} for review in reviews]\n",
        "    df = pd.DataFrame(review_data)\n",
        "    return df"
      ],
      "metadata": {
        "id": "1FlVOs2F89JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "nbTQYabTHbey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preprocessing ---\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stopwords.words('english')]\n",
        "    return \" \".join(words)\n",
        "\n",
        "def preprocess_reviews(df):\n",
        "    df['clean_review'] = df['review'].astype(str).apply(preprocess_text)\n",
        "    df['voted_up'] = df['voted_up'].astype(int)\n",
        "    return df"
      ],
      "metadata": {
        "id": "CVUNygRe9Gv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Function"
      ],
      "metadata": {
        "id": "f1buyNwcHexK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. MODEL TRAINING AND EVALUATION\n",
        "# --------------------------------------------\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Accuracy and Report\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    cm_df = pd.DataFrame(cm, index=['Actual Negative (0)', 'Actual Positive (1)'],\n",
        "                         columns=['Predicted Negative (0)', 'Predicted Positive (1)'])\n",
        "\n",
        "    print(\"Confusion Matrix:\\n\", cm_df)\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=0.5, cbar=False)\n",
        "    plt.title(\"Confusion Matrix Heatmap\")\n",
        "    plt.ylabel(\"Actual Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "U2fvkfur9MNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Flow"
      ],
      "metadata": {
        "id": "lq9LTjOVHmf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Scrape data\n",
        "df_reviews = scrape_reviews_for_single_game('Halo Infinite', 5000)"
      ],
      "metadata": {
        "id": "-iYInVCM9No4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocess\n",
        "df = preprocess_reviews(df_reviews)"
      ],
      "metadata": {
        "id": "0Hi9Fzn69S-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "WMUWMijo9gN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Cloud"
      ],
      "metadata": {
        "id": "b5MUlITpbglz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "# --- Word Cloud ---\n",
        "def plot_wordcloud(text_data, title=\"Word Cloud\"):\n",
        "    text = \" \".join(text_data)\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "# Generate word cloud for cleaned reviews\n",
        "plot_wordcloud(df['clean_review'], title=\"Most Common Words in Reviews\")"
      ],
      "metadata": {
        "id": "KZGbqfSvbWKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_reviews['clean_review'], df_reviews['voted_up'], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "BQEU56mV-8y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Models to Try\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "        \"Naive Bayes\": MultinomialNB(),\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        \"Support Vector Machine (SVM)\": SVC(kernel='linear')\n",
        "    }\n",
        "\n",
        "    # Train and Evaluate Each Model\n",
        "    for model_name, model in models.items():\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Training {model_name}...\")\n",
        "        evaluate_model(model, X_train_tfidf, X_test_tfidf, y_train, y_test)"
      ],
      "metadata": {
        "id": "HDA_t9ws_CrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep learning"
      ],
      "metadata": {
        "id": "y7prjxRJHtLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Conv1D, GlobalMaxPooling1D, GRU, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "def prepare_dl_data(df, vocab_size=10000, max_len=200):\n",
        "    tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "    tokenizer.fit_on_texts(df['clean_review'])\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(df['clean_review'])\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "    return padded_sequences, tokenizer\n",
        "\n",
        "# Plot training history\n",
        "def plot_training_history(history, model_name='Model'):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Train Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Val Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title(f'{model_name} Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Train Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.title(f'{model_name} Loss')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred_probs = model.predict(X_test)\n",
        "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# Dynamic model builder\n",
        "def build_model(model_type, vocab_size, embedding_dim=64, input_length=200):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embedding_dim, input_length=input_length))\n",
        "\n",
        "    if model_type == 'LSTM':\n",
        "        model.add(LSTM(64))\n",
        "    elif model_type == 'BiLSTM':\n",
        "        model.add(Bidirectional(LSTM(64)))\n",
        "    elif model_type == 'GRU':\n",
        "        model.add(GRU(64))\n",
        "    elif model_type == 'CNN':\n",
        "        model.add(Conv1D(128, 5, activation='relu'))\n",
        "        model.add(GlobalMaxPooling1D())\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main function to train deep learning model\n",
        "def train_deep_learning_model(df, model_type='LSTM', vocab_size=10000, max_len=200, embedding_dim=64, epochs=5, batch_size=32):\n",
        "    padded_sequences, tokenizer = prepare_dl_data(df, vocab_size=vocab_size, max_len=max_len)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['voted_up'], test_size=0.2, random_state=42)\n",
        "\n",
        "    model = build_model(model_type, vocab_size, embedding_dim, max_len)\n",
        "    print(f\"Training {model_type}...\")\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=2)\n",
        "\n",
        "    plot_training_history(history, model_name=model_type)\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "    return model\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "def prepare_dl_data(df, vocab_size=10000, max_len=200):\n",
        "    tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "    tokenizer.fit_on_texts(df['clean_review'])\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(df['clean_review'])\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "    return padded_sequences, tokenizer\n",
        "\n",
        "# Plot training history\n",
        "def plot_training_history(history, model_name='Model'):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Train Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Val Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title(f'{model_name} Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Train Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.title(f'{model_name} Loss')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred_probs = model.predict(X_test)\n",
        "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# Dynamic model builder\n",
        "def build_model(model_type, vocab_size, embedding_dim=64, input_length=200):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embedding_dim, input_length=input_length))\n",
        "\n",
        "    if model_type == 'LSTM':\n",
        "        model.add(LSTM(64))\n",
        "    elif model_type == 'BiLSTM':\n",
        "        model.add(Bidirectional(LSTM(64)))\n",
        "    elif model_type == 'GRU':\n",
        "        model.add(GRU(64))\n",
        "    elif model_type == 'CNN':\n",
        "        model.add(Conv1D(128, 5, activation='relu'))\n",
        "        model.add(GlobalMaxPooling1D())\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main function to train deep learning model\n",
        "def train_deep_learning_model(df, model_type='LSTM', vocab_size=10000, max_len=200, embedding_dim=64, epochs=20, batch_size=32):\n",
        "    padded_sequences, tokenizer = prepare_dl_data(df, vocab_size=vocab_size, max_len=max_len)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['voted_up'], test_size=0.2, random_state=42)\n",
        "\n",
        "    model = build_model(model_type, vocab_size, embedding_dim, max_len)\n",
        "    print(f\"Training {model_type}...\")\n",
        "\n",
        "    # Early stopping\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks=[early_stop],\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    plot_training_history(history, model_name=model_type)\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "    return model"
      ],
      "metadata": {
        "id": "C0trX5b3_HWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LSTM\n",
        "lstm_model = train_deep_learning_model(df, model_type='LSTM')"
      ],
      "metadata": {
        "id": "Zj9b1SpT_Ogf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train CNN1\n",
        "cnn_model = train_deep_learning_model(df, model_type='CNN')"
      ],
      "metadata": {
        "id": "wqo67Tfu_wqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train GRU\n",
        "gru_model = train_deep_learning_model(df, model_type='GRU')"
      ],
      "metadata": {
        "id": "DmGzAhYM_0TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train BiLSTM\n",
        "bilstm_model = train_deep_learning_model(df, model_type='BiLSTM')"
      ],
      "metadata": {
        "id": "fC01UgbBvav3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "z-1HckucI55r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from textblob import TextBlob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Concatenate, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# --- Assume your df is already loaded and cleaned ---\n",
        "# If not, load or clean your reviews dataframe here\n",
        "\n",
        "# --- Sentiment Analysis ---\n",
        "def get_sentiment_score(text):\n",
        "    polarity = TextBlob(text).sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return 1\n",
        "    elif polarity < 0:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df['sentiment_score'] = df['review'].astype(str).apply(get_sentiment_score)\n",
        "\n",
        "# --- Tokenization ---\n",
        "max_words = 10000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df['clean_review'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df['clean_review'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "X_text = padded_sequences\n",
        "X_sentiment = df['sentiment_score'].values\n",
        "y = df['voted_up'].values\n",
        "\n",
        "# --- Train/Test Split ---\n",
        "X_text_train, X_text_test, X_sent_train, X_sent_test, y_train, y_test = train_test_split(\n",
        "    X_text, X_sentiment, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Model Definition ---\n",
        "embedding_dim = 64\n",
        "\n",
        "# Input 1: Text\n",
        "text_input = Input(shape=(max_len,), name='text_input')\n",
        "x = Embedding(input_dim=max_words, output_dim=embedding_dim)(text_input)\n",
        "x = Bidirectional(LSTM(64))(x)\n",
        "\n",
        "# Input 2: Sentiment\n",
        "sent_input = Input(shape=(1,), name='sentiment_input')\n",
        "\n",
        "# Combine\n",
        "combined = Concatenate()([x, sent_input])\n",
        "combined = Dropout(0.3)(combined)\n",
        "output = Dense(1, activation='sigmoid')(combined)\n",
        "\n",
        "model = Model(inputs=[text_input, sent_input], outputs=output)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# --- Training ---\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    {'text_input': X_text_train, 'sentiment_input': X_sent_train},\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# --- Evaluation ---\n",
        "loss, accuracy = model.evaluate(\n",
        "    {'text_input': X_text_test, 'sentiment_input': X_sent_test}, y_test)\n",
        "print(f\"\\nTest Accuracy with Sentiment Feature: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "k3hVFkCPBl_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lime"
      ],
      "metadata": {
        "id": "xpj485cbJB9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "id": "gpj5POu3CQPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "an6PQD5QDnkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Negative', 'Positive']  # Assuming binary sentiment\n",
        "max_len = 200  # Should match your BiLSTM input length\n",
        "\n",
        "def lime_predict(texts):\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    padded = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "    probs = bilstm_model.predict(padded)\n",
        "    # Return [prob_negative, prob_positive] format for each sample\n",
        "    return np.hstack((1 - probs, probs))\n"
      ],
      "metadata": {
        "id": "ujZDoVp7Dwbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "\n",
        "# Pick a sample review\n",
        "idx = 0  # index of the test sample\n",
        "sample_text = X_test.iloc[idx]  # this is raw text like \"I loved the game...\"\n",
        "\n",
        "# Explain prediction\n",
        "exp = explainer.explain_instance(sample_text, lime_predict, num_features=10)\n",
        "\n",
        "# Show explanation in notebook\n",
        "exp.show_in_notebook(text=sample_text)\n"
      ],
      "metadata": {
        "id": "OitjqiJ7ET-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize explanation\n",
        "fig = exp.as_pyplot_figure(label=1)\n",
        "plt.title(\"LIME Explanation for BiLSTM+Sentiment Model\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TsqPgYuxWWS4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}